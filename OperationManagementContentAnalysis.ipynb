{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmJXZSGXy/P/teQyvJvhzA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaminAung1/cv/blob/main/OperationManagementContentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "-emJC9NqnF_X",
        "outputId": "c36e9f7b-ba86-4c6c-f745-8b95e8d9da4f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-edca98c24840>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load your data (Update the path to the location of your CSV file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Google Health Screening.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Function to clean and tokenize text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Load your data (Update the path to the location of your CSV file)\n",
        "data = pd.read_csv('Google Health Screening.xlsx')\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words in the reviews\n",
        "word_counts = Counter()\n",
        "data['review_text'].apply(lambda x: word_counts.update(preprocess(x)))\n",
        "\n",
        "# Display most common words\n",
        "most_common_words = word_counts.most_common(50)  # You can adjust the number as needed\n",
        "print(most_common_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Load your data (make sure to use the correct path to your Excel file)\n",
        "data = pd.read_excel('Google Health Screening.xlsx')\n",
        "\n",
        "# If your Excel file has multiple sheets, you might need to specify the sheet_name:\n",
        "# data = pd.read_excel('path_to_your_reviews.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words in the reviews\n",
        "word_counts = Counter()\n",
        "data['Reviews'].apply(lambda x: word_counts.update(preprocess(x)))  # Ensure 'review_text' is the correct column name\n",
        "\n",
        "# Display most common words\n",
        "most_common_words = word_counts.most_common(50)  # You can adjust the number as needed\n",
        "print(most_common_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nJbNQPNnux6",
        "outputId": "67ae4650-b861-456a-da49-7bb45929a949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 659), ('and', 616), ('screening', 404), ('to', 370), ('health', 354), ('for', 328), ('i', 266), ('is', 210), ('very', 188), ('my', 179), ('good', 158), ('here', 147), ('staff', 144), ('a', 141), ('service', 140), ('are', 134), ('with', 130), ('was', 129), ('friendly', 126), ('hospital', 126), ('in', 114), ('all', 105), ('at', 103), ('of', 103), ('time', 98), ('it', 85), ('this', 81), ('helpful', 79), ('beacon', 78), ('have', 73), ('on', 72), ('they', 72), ('experience', 72), ('you', 70), ('me', 69), ('that', 65), ('so', 63), ('test', 62), ('as', 60), ('were', 59), ('waiting', 57), ('lunch', 57), ('their', 53), ('from', 53), ('but', 49), ('first', 49), ('came', 49), ('provided', 49), ('staffs', 48), ('process', 47)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_excel('Google Health Screening.xlsx')  # Adjust the file path and sheet if necessary\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words in the reviews\n",
        "word_counts = Counter()\n",
        "data['Reviews'].apply(lambda x: word_counts.update(preprocess(x)))  # Ensure 'review_text' is the correct column name\n",
        "\n",
        "# Convert the counter to a DataFrame\n",
        "word_freq_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency'])\n",
        "\n",
        "# Filter the DataFrame to include only words with frequency of 3 or more\n",
        "word_freq_df = word_freq_df[word_freq_df['Frequency'] >= 3]\n",
        "\n",
        "# Sort the DataFrame by frequency in descending order\n",
        "word_freq_df = word_freq_df.sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "# Output the data to an Excel file\n",
        "word_freq_df.to_excel('word_frequencies.xlsx', index=False)\n",
        "\n",
        "# Print the top 50 most common words to check (or the entire filtered list if fewer than 50)\n",
        "print(word_freq_df.head(50))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shclfQI0pDj4",
        "outputId": "d0996097-568a-491e-b249-1befacdf8c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Word  Frequency\n",
            "9            the        659\n",
            "21           and        616\n",
            "30     screening        404\n",
            "24            to        370\n",
            "66        health        354\n",
            "15           for        328\n",
            "106            i        266\n",
            "188           is        210\n",
            "208         very        188\n",
            "92            my        179\n",
            "605         good        158\n",
            "300         here        147\n",
            "116        staff        144\n",
            "320            a        141\n",
            "365      service        140\n",
            "601          are        134\n",
            "198         with        130\n",
            "332          was        129\n",
            "211     friendly        126\n",
            "331     hospital        126\n",
            "199           in        114\n",
            "190          all        105\n",
            "80            at        103\n",
            "114           of        103\n",
            "242         time         98\n",
            "167           it         85\n",
            "29          this         81\n",
            "1097     helpful         79\n",
            "291       beacon         78\n",
            "311         have         73\n",
            "162         they         72\n",
            "329   experience         72\n",
            "69            on         72\n",
            "5            you         70\n",
            "99            me         69\n",
            "144         that         65\n",
            "16            so         63\n",
            "20          test         62\n",
            "147           as         60\n",
            "508         were         59\n",
            "14       waiting         57\n",
            "221        lunch         57\n",
            "205        their         53\n",
            "406         from         53\n",
            "305         came         49\n",
            "602     provided         49\n",
            "289        first         49\n",
            "71           but         49\n",
            "551       staffs         48\n",
            "360         well         47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_words = {'good',\n",
        "'friendly',\n",
        "'helpful',\n",
        "'well',\n",
        "'fast',\n",
        "'great',\n",
        "'recommend',\n",
        "'efficient',\n",
        "'patient',\n",
        "'polite',\n",
        "'recommended',\n",
        "'professional',\n",
        "'thank',\n",
        "'excellent',\n",
        "'thanks',\n",
        "'smooth',\n",
        "'best',\n",
        "'comfortable',\n",
        "'pleasant',\n",
        "'satisfied',\n",
        "'happy',\n",
        "'clear',\n",
        "'impressed',\n",
        "'super',\n",
        "'better',\n",
        "'special',\n",
        "'affordable',\n",
        "'smoothly',\n",
        "'love',\n",
        "'clean',\n",
        "'comprehensive',\n",
        "'superb',\n",
        "'awesome',\n",
        "'systematic',\n",
        "'organised',\n",
        "'fantastic',\n",
        "'knowledgeable',\n",
        "'smile',\n",
        "'pretty',\n",
        "'appreciate',\n",
        "'wonderful',\n",
        "'positive',\n",
        "'organized',\n",
        "'approachable',\n",
        "'kudos',\n",
        "'efficiently',\n",
        "'responsive',\n",
        "'glad',\n",
        "'acceptable',\n",
        "'patience',\n",
        "'corporate',\n",
        "'amazing',\n",
        "'gentle'}\n",
        "negative_words = {'worst',\n",
        "'bad',\n",
        "'slow',\n",
        "'missed',\n",
        "'stress',\n",
        "'terrible',\n",
        "'delay',\n",
        "'horrible',\n",
        "'unpleasant',\n",
        "'worried'}\n",
        "neutral_words = {'screening',\n",
        "'health',\n",
        "'staff',\n",
        "'service',\n",
        "'hospital',\n",
        "'time',\n",
        "'experience',\n",
        "'waiting',\n",
        "'lunch',\n",
        "'provided',\n",
        "'first',\n",
        "'staffs',\n",
        "'process',\n",
        "'breakfast',\n",
        "'doctor',\n",
        "'nurses',\n",
        "'food',\n",
        "'report',\n",
        "'people',\n",
        "'wait',\n",
        "'free',\n",
        "'overall',\n",
        "'doctors',\n",
        "'customer',\n",
        "'package',\n",
        "'check',\n",
        "'services',\n",
        "'many',\n",
        "'would',\n",
        "'day',\n",
        "'patients',\n",
        "'ultrasound',\n",
        "'hours',\n",
        "'need',\n",
        "'today',\n",
        "'parking',\n",
        "'went',\n",
        "'long',\n",
        "'highly',\n",
        "'nurse',\n",
        "'registration',\n",
        "'make',\n",
        "'same',\n",
        "'medical',\n",
        "'still',\n",
        "'provide',\n",
        "'feel',\n",
        "'visit',\n",
        "'than',\n",
        "'dr',\n",
        "'during',\n",
        "'queue',\n",
        "'full',\n",
        "'number',\n",
        "'took',\n",
        "'cancer',\n",
        "'attentive',\n",
        "'name',\n",
        "'our',\n",
        "'nice',\n",
        "'team',\n",
        "'last',\n",
        "'quite',\n",
        "'take',\n",
        "'other',\n",
        "'care',\n",
        "'blood',\n",
        "'some',\n",
        "'definitely',\n",
        "'especially',\n",
        "'follow',\n",
        "'next',\n",
        "'got',\n",
        "'about',\n",
        "'waited',\n",
        "'angeline',\n",
        "'price',\n",
        "'screen',\n",
        "'annual',\n",
        "'now',\n",
        "'environment',\n",
        "'tests',\n",
        "'keep',\n",
        "'hour',\n",
        "'help',\n",
        "'sure',\n",
        "'consultation',\n",
        "'those',\n",
        "'department',\n",
        "'counter',\n",
        "'coming',\n",
        "'room',\n",
        "'ok',\n",
        "'flow',\n",
        "'early',\n",
        "'appointment',\n",
        "'kind',\n",
        "'year',\n",
        "'hope',\n",
        "'finished',\n",
        "'how',\n",
        "'ready',\n",
        "'avoid',\n",
        "'crowd',\n",
        "'such',\n",
        "'completed',\n",
        "'compared',\n",
        "'told',\n",
        "'turn',\n",
        "'result',\n",
        "'job',\n",
        "'review',\n",
        "'since',\n",
        "'start',\n",
        "'think',\n",
        "'treatment',\n",
        "'work',\n",
        "'serve',\n",
        "'less',\n",
        "'friends',\n",
        "'explanation',\n",
        "'results',\n",
        "'family',\n",
        "'promotion',\n",
        "'arrived',\n",
        "'screenings',\n",
        "'morning',\n",
        "'without',\n",
        "'system',\n",
        "'years',\n",
        "'find',\n",
        "'packages',\n",
        "'should',\n",
        "'floor',\n",
        "'received',\n",
        "'hospitality',\n",
        "'reports',\n",
        "'procedure',\n",
        "'helped',\n",
        "'chicken',\n",
        "'said',\n",
        "'later',\n",
        "'through',\n",
        "'explain',\n",
        "'explained',\n",
        "'warm',\n",
        "'checking',\n",
        "'healthy',\n",
        "'met',\n",
        "'handle',\n",
        "'thumbs',\n",
        "'meals',\n",
        "'plus',\n",
        "'must',\n",
        "'fasting',\n",
        "'simple',\n",
        "'appointments',\n",
        "'progress',\n",
        "'lady',\n",
        "'quick',\n",
        "'consultancy',\n",
        "'caring',\n",
        "'ensure',\n",
        "'offer',\n",
        "'assessment',\n",
        "'served',\n",
        "'reasonable',\n",
        "'available',\n",
        "'taken',\n",
        "'drinks',\n",
        "'tasty',\n",
        "'attending',\n",
        "'delicious',\n",
        "'guidance',\n",
        "'felt',\n",
        "'hospitals',\n",
        "'truly',\n",
        "'far',\n",
        "'meal',\n",
        "'doc',\n",
        "'reached',\n",
        "'treated',\n",
        "'complete',\n",
        "'opposite',\n",
        "'section',\n",
        "'packed',\n",
        "'easy',\n",
        "'examination',\n",
        "'made',\n",
        "'attended',\n",
        "'gave',\n",
        "'level',\n",
        "'stars',\n",
        "'home',\n",
        "'throughout',\n",
        "'however',\n",
        "'customers',\n",
        "'most',\n",
        "'god',\n",
        "'continue',\n",
        "'drs',\n",
        "'despite',\n",
        "'detailed',\n",
        "'tea',\n",
        "'entire',\n",
        "'way',\n",
        "'light',\n",
        "'space',\n",
        "'making',\n",
        "'improve',\n",
        "'body',\n",
        "'credit',\n",
        "'able',\n",
        "'sorry',\n",
        "'own',\n",
        "'longer',\n",
        "'collect',\n",
        "'mentioned',\n",
        "'answer',\n",
        "'officers',\n",
        "'thorough',\n",
        "'point',\n",
        "'info',\n",
        "'included',\n",
        "'attitude',\n",
        "'once',\n",
        "'complimentary',\n",
        "'hot',\n",
        "'reviews',\n",
        "'different',\n",
        "'covid',\n",
        "'sop',\n",
        "'finish',\n",
        "'management',\n",
        "'details',\n",
        "'phone',\n",
        "'hrs',\n",
        "'earlier',\n",
        "'payment',\n",
        "'private',\n",
        "'taking',\n",
        "'detail',\n",
        "'ecg',\n",
        "'scan',\n",
        "'want',\n",
        "'given',\n",
        "'difference',\n",
        "'heath',\n",
        "'over',\n",
        "'cheap',\n",
        "'weekday',\n",
        "'cost',\n",
        "'step',\n",
        "'assist',\n",
        "'eye',\n",
        "'wanted',\n",
        "'mom',\n",
        "'guide',\n",
        "'closely',\n",
        "'timer',\n",
        "'buffet',\n",
        "'personnel',\n",
        "'assisting',\n",
        "'quickly',\n",
        "'meet',\n",
        "'rest',\n",
        "'ensuring',\n",
        "'healthcare',\n",
        "'plenty',\n",
        "'yearly',\n",
        "'never',\n",
        "'whatsapp',\n",
        "'bone',\n",
        "'nathan',\n",
        "'vegetarian',\n",
        "'journey',\n",
        "'relatives',\n",
        "'month',\n",
        "'mandy',\n",
        "'courteous',\n",
        "'welcoming',\n",
        "'speed',\n",
        "'recently',\n",
        "'try',\n",
        "'providing',\n",
        "'large',\n",
        "'facilities',\n",
        "'pressure',\n",
        "'explaining',\n",
        "'eat',\n",
        "'trained',\n",
        "'money',\n",
        "'pasar',\n",
        "'chest',\n",
        "'takes',\n",
        "'normal',\n",
        "'slot',\n",
        "'walking',\n",
        "'similar',\n",
        "'absolutely',\n",
        "'ray',\n",
        "'email',\n",
        "'soon',\n",
        "'away',\n",
        "'urine',\n",
        "'file',\n",
        "'twice',\n",
        "'change',\n",
        "'loud',\n",
        "'leave',\n",
        "'inform',\n",
        "'xray',\n",
        "'week',\n",
        "'few',\n",
        "'complain',\n",
        "'foods',\n",
        "'friend',\n",
        "'procedures',\n",
        "'extremely',\n",
        "'saturday',\n",
        "'right',\n",
        "'okay',\n",
        "'give',\n",
        "'gift',\n",
        "'checks',\n",
        "'supporting',\n",
        "'visited',\n",
        "'return',\n",
        "'coordination',\n",
        "'nothing',\n",
        "'head',\n",
        "'high',\n",
        "'busy',\n",
        "'please',\n",
        "'extra',\n",
        "'abdomen',\n",
        "'star',\n",
        "'information',\n",
        "'rating',\n",
        "'needs',\n",
        "'discount',\n",
        "'note',\n",
        "'feeling',\n",
        "'indeed'}"
      ],
      "metadata": {
        "id": "GAsQar1Hvuo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_excel('Google Health Screening.xlsx')  # Adjust the file path and sheet if necessary\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words and co-occurrences with \"ultrasound\"\n",
        "word_counts = Counter()\n",
        "co_occurrences = defaultdict(int)\n",
        "ultrasound_reviews = []\n",
        "\n",
        "data['Reviews'].apply(lambda review: ultrasound_reviews.append(review) if 'ultrasound' in review.lower() else None)\n",
        "\n",
        "for review in ultrasound_reviews:\n",
        "    words = preprocess(review)\n",
        "    unique_words = set(words)\n",
        "    if 'ultrasound' in unique_words:\n",
        "        for word in unique_words:\n",
        "            if word != 'ultrasound':\n",
        "                co_occurrences[word] += 1\n",
        "\n",
        "# Calculate fuzzy sentiment scores\n",
        "def fuzzy_sentiment_scores(target, co_occurrences):\n",
        "    scores = {'Positive': 0, 'Negative': 0, 'Neutral': 0}\n",
        "    for word, count in co_occurrences.items():\n",
        "        if word in positive_words:\n",
        "            scores['Positive'] += count\n",
        "        elif word in negative_words:\n",
        "            scores['Negative'] += count\n",
        "        elif word in neutral_words:\n",
        "            scores['Neutral'] += count\n",
        "    return scores\n",
        "\n",
        "# Get sentiment scores for 'ultrasound'\n",
        "ultrasound_scores = fuzzy_sentiment_scores('ultrasound', co_occurrences)\n",
        "print(ultrasound_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG3VVXQJxKjz",
        "outputId": "0cf0e26d-7355-41e5-b9c9-0dbdc75e0837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Positive': 55, 'Negative': 15, 'Neutral': 466}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_excel('Google Health Screening.xlsx')  # Adjust the file path and sheet if necessary\n",
        "\n",
        "# Define word categories\n",
        "positive_words = {'good',\n",
        "'friendly',\n",
        "'helpful',\n",
        "'well',\n",
        "'fast',\n",
        "'great',\n",
        "'recommend',\n",
        "'efficient',\n",
        "'patient',\n",
        "'polite',\n",
        "'recommended',\n",
        "'professional',\n",
        "'thank',\n",
        "'excellent',\n",
        "'thanks',\n",
        "'smooth',\n",
        "'best',\n",
        "'comfortable',\n",
        "'pleasant',\n",
        "'satisfied',\n",
        "'happy',\n",
        "'clear',\n",
        "'impressed',\n",
        "'super',\n",
        "'better',\n",
        "'special',\n",
        "'affordable',\n",
        "'smoothly',\n",
        "'love',\n",
        "'clean',\n",
        "'comprehensive',\n",
        "'superb',\n",
        "'awesome',\n",
        "'systematic',\n",
        "'organised',\n",
        "'fantastic',\n",
        "'knowledgeable',\n",
        "'smile',\n",
        "'pretty',\n",
        "'appreciate',\n",
        "'wonderful',\n",
        "'positive',\n",
        "'organized',\n",
        "'approachable',\n",
        "'kudos',\n",
        "'efficiently',\n",
        "'responsive',\n",
        "'glad',\n",
        "'acceptable',\n",
        "'patience',\n",
        "'corporate',\n",
        "'amazing',\n",
        "'gentle'}\n",
        "negative_words = {'worst',\n",
        "'bad',\n",
        "'slow',\n",
        "'missed',\n",
        "'stress',\n",
        "'terrible',\n",
        "'delay',\n",
        "'horrible',\n",
        "'unpleasant',\n",
        "'worried'}\n",
        "neutral_words = {'screening',\n",
        "'health',\n",
        "'staff',\n",
        "'service',\n",
        "'hospital',\n",
        "'time',\n",
        "'experience',\n",
        "'waiting',\n",
        "'lunch',\n",
        "'provided',\n",
        "'first',\n",
        "'staffs',\n",
        "'process',\n",
        "'breakfast',\n",
        "'doctor',\n",
        "'nurses',\n",
        "'food',\n",
        "'report',\n",
        "'people',\n",
        "'wait',\n",
        "'free',\n",
        "'overall',\n",
        "'doctors',\n",
        "'customer',\n",
        "'package',\n",
        "'check',\n",
        "'services',\n",
        "'many',\n",
        "'would',\n",
        "'day',\n",
        "'patients',\n",
        "'ultrasound',\n",
        "'hours',\n",
        "'need',\n",
        "'today',\n",
        "'parking',\n",
        "'went',\n",
        "'long',\n",
        "'highly',\n",
        "'nurse',\n",
        "'registration',\n",
        "'make',\n",
        "'same',\n",
        "'medical',\n",
        "'still',\n",
        "'provide',\n",
        "'feel',\n",
        "'visit',\n",
        "'than',\n",
        "'dr',\n",
        "'during',\n",
        "'queue',\n",
        "'full',\n",
        "'number',\n",
        "'took',\n",
        "'cancer',\n",
        "'attentive',\n",
        "'name',\n",
        "'our',\n",
        "'nice',\n",
        "'team',\n",
        "'last',\n",
        "'quite',\n",
        "'take',\n",
        "'other',\n",
        "'care',\n",
        "'blood',\n",
        "'some',\n",
        "'definitely',\n",
        "'especially',\n",
        "'follow',\n",
        "'next',\n",
        "'got',\n",
        "'about',\n",
        "'waited',\n",
        "'angeline',\n",
        "'price',\n",
        "'screen',\n",
        "'annual',\n",
        "'now',\n",
        "'environment',\n",
        "'tests',\n",
        "'keep',\n",
        "'hour',\n",
        "'help',\n",
        "'sure',\n",
        "'consultation',\n",
        "'those',\n",
        "'department',\n",
        "'counter',\n",
        "'coming',\n",
        "'room',\n",
        "'ok',\n",
        "'flow',\n",
        "'early',\n",
        "'appointment',\n",
        "'kind',\n",
        "'year',\n",
        "'hope',\n",
        "'finished',\n",
        "'how',\n",
        "'ready',\n",
        "'avoid',\n",
        "'crowd',\n",
        "'such',\n",
        "'completed',\n",
        "'compared',\n",
        "'told',\n",
        "'turn',\n",
        "'result',\n",
        "'job',\n",
        "'review',\n",
        "'since',\n",
        "'start',\n",
        "'think',\n",
        "'treatment',\n",
        "'work',\n",
        "'serve',\n",
        "'less',\n",
        "'friends',\n",
        "'explanation',\n",
        "'results',\n",
        "'family',\n",
        "'promotion',\n",
        "'arrived',\n",
        "'screenings',\n",
        "'morning',\n",
        "'without',\n",
        "'system',\n",
        "'years',\n",
        "'find',\n",
        "'packages',\n",
        "'should',\n",
        "'floor',\n",
        "'received',\n",
        "'hospitality',\n",
        "'reports',\n",
        "'procedure',\n",
        "'helped',\n",
        "'chicken',\n",
        "'said',\n",
        "'later',\n",
        "'through',\n",
        "'explain',\n",
        "'explained',\n",
        "'warm',\n",
        "'checking',\n",
        "'healthy',\n",
        "'met',\n",
        "'handle',\n",
        "'thumbs',\n",
        "'meals',\n",
        "'plus',\n",
        "'must',\n",
        "'fasting',\n",
        "'simple',\n",
        "'appointments',\n",
        "'progress',\n",
        "'lady',\n",
        "'quick',\n",
        "'consultancy',\n",
        "'caring',\n",
        "'ensure',\n",
        "'offer',\n",
        "'assessment',\n",
        "'served',\n",
        "'reasonable',\n",
        "'available',\n",
        "'taken',\n",
        "'drinks',\n",
        "'tasty',\n",
        "'attending',\n",
        "'delicious',\n",
        "'guidance',\n",
        "'felt',\n",
        "'hospitals',\n",
        "'truly',\n",
        "'far',\n",
        "'meal',\n",
        "'doc',\n",
        "'reached',\n",
        "'treated',\n",
        "'complete',\n",
        "'opposite',\n",
        "'section',\n",
        "'packed',\n",
        "'easy',\n",
        "'examination',\n",
        "'made',\n",
        "'attended',\n",
        "'gave',\n",
        "'level',\n",
        "'stars',\n",
        "'home',\n",
        "'throughout',\n",
        "'however',\n",
        "'customers',\n",
        "'most',\n",
        "'god',\n",
        "'continue',\n",
        "'drs',\n",
        "'despite',\n",
        "'detailed',\n",
        "'tea',\n",
        "'entire',\n",
        "'way',\n",
        "'light',\n",
        "'space',\n",
        "'making',\n",
        "'improve',\n",
        "'body',\n",
        "'credit',\n",
        "'able',\n",
        "'sorry',\n",
        "'own',\n",
        "'longer',\n",
        "'collect',\n",
        "'mentioned',\n",
        "'answer',\n",
        "'officers',\n",
        "'thorough',\n",
        "'point',\n",
        "'info',\n",
        "'included',\n",
        "'attitude',\n",
        "'once',\n",
        "'complimentary',\n",
        "'hot',\n",
        "'reviews',\n",
        "'different',\n",
        "'covid',\n",
        "'sop',\n",
        "'finish',\n",
        "'management',\n",
        "'details',\n",
        "'phone',\n",
        "'hrs',\n",
        "'earlier',\n",
        "'payment',\n",
        "'private',\n",
        "'taking',\n",
        "'detail',\n",
        "'ecg',\n",
        "'scan',\n",
        "'want',\n",
        "'given',\n",
        "'difference',\n",
        "'heath',\n",
        "'over',\n",
        "'cheap',\n",
        "'weekday',\n",
        "'cost',\n",
        "'step',\n",
        "'assist',\n",
        "'eye',\n",
        "'wanted',\n",
        "'mom',\n",
        "'guide',\n",
        "'closely',\n",
        "'timer',\n",
        "'buffet',\n",
        "'personnel',\n",
        "'assisting',\n",
        "'quickly',\n",
        "'meet',\n",
        "'rest',\n",
        "'ensuring',\n",
        "'healthcare',\n",
        "'plenty',\n",
        "'yearly',\n",
        "'never',\n",
        "'whatsapp',\n",
        "'bone',\n",
        "'nathan',\n",
        "'vegetarian',\n",
        "'journey',\n",
        "'relatives',\n",
        "'month',\n",
        "'mandy',\n",
        "'courteous',\n",
        "'welcoming',\n",
        "'speed',\n",
        "'recently',\n",
        "'try',\n",
        "'providing',\n",
        "'large',\n",
        "'facilities',\n",
        "'pressure',\n",
        "'explaining',\n",
        "'eat',\n",
        "'trained',\n",
        "'money',\n",
        "'pasar',\n",
        "'chest',\n",
        "'takes',\n",
        "'normal',\n",
        "'slot',\n",
        "'walking',\n",
        "'similar',\n",
        "'absolutely',\n",
        "'ray',\n",
        "'email',\n",
        "'soon',\n",
        "'away',\n",
        "'urine',\n",
        "'file',\n",
        "'twice',\n",
        "'change',\n",
        "'loud',\n",
        "'leave',\n",
        "'inform',\n",
        "'xray',\n",
        "'week',\n",
        "'few',\n",
        "'complain',\n",
        "'foods',\n",
        "'friend',\n",
        "'procedures',\n",
        "'extremely',\n",
        "'saturday',\n",
        "'right',\n",
        "'okay',\n",
        "'give',\n",
        "'gift',\n",
        "'checks',\n",
        "'supporting',\n",
        "'visited',\n",
        "'return',\n",
        "'coordination',\n",
        "'nothing',\n",
        "'head',\n",
        "'high',\n",
        "'busy',\n",
        "'please',\n",
        "'extra',\n",
        "'abdomen',\n",
        "'star',\n",
        "'information',\n",
        "'rating',\n",
        "'needs',\n",
        "'discount',\n",
        "'note',\n",
        "'feeling',\n",
        "'indeed'}\n",
        "\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words and co-occurrences with \"ultrasound\"\n",
        "word_counts = Counter()\n",
        "co_occurrences = defaultdict(int)\n",
        "ultrasound_reviews = []\n",
        "\n",
        "data['Reviews'].apply(lambda review: ultrasound_reviews.append(review) if 'ultrasound' in review.lower() else None)\n",
        "\n",
        "for review in ultrasound_reviews:\n",
        "    words = preprocess(review)\n",
        "    unique_words = set(words)\n",
        "    if 'ultrasound' in unique_words:\n",
        "        for word in unique_words:\n",
        "            if word != 'ultrasound':\n",
        "                co_occurrences[word] += 1\n",
        "\n",
        "# Normalize co-occurrence counts\n",
        "total_co_occurrences = sum(co_occurrences.values())\n",
        "normalized_co_occurrences = {word: count / total_co_occurrences for word, count in co_occurrences.items()}\n"
      ],
      "metadata": {
        "id": "YL3sh6SdxxmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataFrame\n",
        "data_entries = []\n",
        "for word, score in normalized_co_occurrences.items():\n",
        "    if word in positive_words:\n",
        "        data_entries.append({'Category': 'Positive', 'Word': word, 'Relationship': score})\n",
        "    elif word in negative_words:\n",
        "        data_entries.append({'Category': 'Negative', 'Word': word, 'Relationship': score})\n",
        "    elif word in neutral_words:\n",
        "        data_entries.append({'Category': 'Neutral', 'Word': word, 'Relationship': score})\n",
        "\n",
        "# Create DataFrame\n",
        "sentiment_df = pd.DataFrame(data_entries)\n",
        "\n",
        "# Save to Excel\n",
        "sentiment_df.to_excel('ultrasound_word_relationships.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "YIVTrUAkyC_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_excel('Google Health Screening.xlsx')  # Adjust the file path and sheet if necessary\n",
        "\n",
        "# Define word categories\n",
        "positive_words = {'good',\n",
        "'friendly',\n",
        "'helpful',\n",
        "'well',\n",
        "'fast',\n",
        "'great',\n",
        "'recommend',\n",
        "'efficient',\n",
        "'patient',\n",
        "'polite',\n",
        "'recommended',\n",
        "'professional',\n",
        "'thank',\n",
        "'excellent',\n",
        "'thanks',\n",
        "'smooth',\n",
        "'best',\n",
        "'comfortable',\n",
        "'pleasant',\n",
        "'satisfied',\n",
        "'happy',\n",
        "'clear',\n",
        "'impressed',\n",
        "'super',\n",
        "'better',\n",
        "'special',\n",
        "'affordable',\n",
        "'smoothly',\n",
        "'love',\n",
        "'clean',\n",
        "'comprehensive',\n",
        "'superb',\n",
        "'awesome',\n",
        "'systematic',\n",
        "'organised',\n",
        "'fantastic',\n",
        "'knowledgeable',\n",
        "'smile',\n",
        "'pretty',\n",
        "'appreciate',\n",
        "'wonderful',\n",
        "'positive',\n",
        "'organized',\n",
        "'approachable',\n",
        "'kudos',\n",
        "'efficiently',\n",
        "'responsive',\n",
        "'glad',\n",
        "'acceptable',\n",
        "'patience',\n",
        "'corporate',\n",
        "'amazing',\n",
        "'gentle'}\n",
        "negative_words = {'worst',\n",
        "'bad',\n",
        "'slow',\n",
        "'missed',\n",
        "'stress',\n",
        "'terrible',\n",
        "'delay',\n",
        "'horrible',\n",
        "'unpleasant',\n",
        "'worried'}\n",
        "neutral_words = {'screening',\n",
        "'health',\n",
        "'staff',\n",
        "'service',\n",
        "'hospital',\n",
        "'time',\n",
        "'experience',\n",
        "'waiting',\n",
        "'lunch',\n",
        "'provided',\n",
        "'first',\n",
        "'staffs',\n",
        "'process',\n",
        "'breakfast',\n",
        "'doctor',\n",
        "'nurses',\n",
        "'food',\n",
        "'report',\n",
        "'people',\n",
        "'wait',\n",
        "'free',\n",
        "'overall',\n",
        "'doctors',\n",
        "'customer',\n",
        "'package',\n",
        "'check',\n",
        "'services',\n",
        "'many',\n",
        "'would',\n",
        "'day',\n",
        "'patients',\n",
        "'ultrasound',\n",
        "'hours',\n",
        "'need',\n",
        "'today',\n",
        "'parking',\n",
        "'went',\n",
        "'long',\n",
        "'highly',\n",
        "'nurse',\n",
        "'registration',\n",
        "'make',\n",
        "'same',\n",
        "'medical',\n",
        "'still',\n",
        "'provide',\n",
        "'feel',\n",
        "'visit',\n",
        "'than',\n",
        "'dr',\n",
        "'during',\n",
        "'queue',\n",
        "'full',\n",
        "'number',\n",
        "'took',\n",
        "'cancer',\n",
        "'attentive',\n",
        "'name',\n",
        "'our',\n",
        "'nice',\n",
        "'team',\n",
        "'last',\n",
        "'quite',\n",
        "'take',\n",
        "'other',\n",
        "'care',\n",
        "'blood',\n",
        "'some',\n",
        "'definitely',\n",
        "'especially',\n",
        "'follow',\n",
        "'next',\n",
        "'got',\n",
        "'about',\n",
        "'waited',\n",
        "'angeline',\n",
        "'price',\n",
        "'screen',\n",
        "'annual',\n",
        "'now',\n",
        "'environment',\n",
        "'tests',\n",
        "'keep',\n",
        "'hour',\n",
        "'help',\n",
        "'sure',\n",
        "'consultation',\n",
        "'those',\n",
        "'department',\n",
        "'counter',\n",
        "'coming',\n",
        "'room',\n",
        "'ok',\n",
        "'flow',\n",
        "'early',\n",
        "'appointment',\n",
        "'kind',\n",
        "'year',\n",
        "'hope',\n",
        "'finished',\n",
        "'how',\n",
        "'ready',\n",
        "'avoid',\n",
        "'crowd',\n",
        "'such',\n",
        "'completed',\n",
        "'compared',\n",
        "'told',\n",
        "'turn',\n",
        "'result',\n",
        "'job',\n",
        "'review',\n",
        "'since',\n",
        "'start',\n",
        "'think',\n",
        "'treatment',\n",
        "'work',\n",
        "'serve',\n",
        "'less',\n",
        "'friends',\n",
        "'explanation',\n",
        "'results',\n",
        "'family',\n",
        "'promotion',\n",
        "'arrived',\n",
        "'screenings',\n",
        "'morning',\n",
        "'without',\n",
        "'system',\n",
        "'years',\n",
        "'find',\n",
        "'packages',\n",
        "'should',\n",
        "'floor',\n",
        "'received',\n",
        "'hospitality',\n",
        "'reports',\n",
        "'procedure',\n",
        "'helped',\n",
        "'chicken',\n",
        "'said',\n",
        "'later',\n",
        "'through',\n",
        "'explain',\n",
        "'explained',\n",
        "'warm',\n",
        "'checking',\n",
        "'healthy',\n",
        "'met',\n",
        "'handle',\n",
        "'thumbs',\n",
        "'meals',\n",
        "'plus',\n",
        "'must',\n",
        "'fasting',\n",
        "'simple',\n",
        "'appointments',\n",
        "'progress',\n",
        "'lady',\n",
        "'quick',\n",
        "'consultancy',\n",
        "'caring',\n",
        "'ensure',\n",
        "'offer',\n",
        "'assessment',\n",
        "'served',\n",
        "'reasonable',\n",
        "'available',\n",
        "'taken',\n",
        "'drinks',\n",
        "'tasty',\n",
        "'attending',\n",
        "'delicious',\n",
        "'guidance',\n",
        "'felt',\n",
        "'hospitals',\n",
        "'truly',\n",
        "'far',\n",
        "'meal',\n",
        "'doc',\n",
        "'reached',\n",
        "'treated',\n",
        "'complete',\n",
        "'opposite',\n",
        "'section',\n",
        "'packed',\n",
        "'easy',\n",
        "'examination',\n",
        "'made',\n",
        "'attended',\n",
        "'gave',\n",
        "'level',\n",
        "'stars',\n",
        "'home',\n",
        "'throughout',\n",
        "'however',\n",
        "'customers',\n",
        "'most',\n",
        "'god',\n",
        "'continue',\n",
        "'drs',\n",
        "'despite',\n",
        "'detailed',\n",
        "'tea',\n",
        "'entire',\n",
        "'way',\n",
        "'light',\n",
        "'space',\n",
        "'making',\n",
        "'improve',\n",
        "'body',\n",
        "'credit',\n",
        "'able',\n",
        "'sorry',\n",
        "'own',\n",
        "'longer',\n",
        "'collect',\n",
        "'mentioned',\n",
        "'answer',\n",
        "'officers',\n",
        "'thorough',\n",
        "'point',\n",
        "'info',\n",
        "'included',\n",
        "'attitude',\n",
        "'once',\n",
        "'complimentary',\n",
        "'hot',\n",
        "'reviews',\n",
        "'different',\n",
        "'covid',\n",
        "'sop',\n",
        "'finish',\n",
        "'management',\n",
        "'details',\n",
        "'phone',\n",
        "'hrs',\n",
        "'earlier',\n",
        "'payment',\n",
        "'private',\n",
        "'taking',\n",
        "'detail',\n",
        "'ecg',\n",
        "'scan',\n",
        "'want',\n",
        "'given',\n",
        "'difference',\n",
        "'heath',\n",
        "'over',\n",
        "'cheap',\n",
        "'weekday',\n",
        "'cost',\n",
        "'step',\n",
        "'assist',\n",
        "'eye',\n",
        "'wanted',\n",
        "'mom',\n",
        "'guide',\n",
        "'closely',\n",
        "'timer',\n",
        "'buffet',\n",
        "'personnel',\n",
        "'assisting',\n",
        "'quickly',\n",
        "'meet',\n",
        "'rest',\n",
        "'ensuring',\n",
        "'healthcare',\n",
        "'plenty',\n",
        "'yearly',\n",
        "'never',\n",
        "'whatsapp',\n",
        "'bone',\n",
        "'nathan',\n",
        "'vegetarian',\n",
        "'journey',\n",
        "'relatives',\n",
        "'month',\n",
        "'mandy',\n",
        "'courteous',\n",
        "'welcoming',\n",
        "'speed',\n",
        "'recently',\n",
        "'try',\n",
        "'providing',\n",
        "'large',\n",
        "'facilities',\n",
        "'pressure',\n",
        "'explaining',\n",
        "'eat',\n",
        "'trained',\n",
        "'money',\n",
        "'pasar',\n",
        "'chest',\n",
        "'takes',\n",
        "'normal',\n",
        "'slot',\n",
        "'walking',\n",
        "'similar',\n",
        "'absolutely',\n",
        "'ray',\n",
        "'email',\n",
        "'soon',\n",
        "'away',\n",
        "'urine',\n",
        "'file',\n",
        "'twice',\n",
        "'change',\n",
        "'loud',\n",
        "'leave',\n",
        "'inform',\n",
        "'xray',\n",
        "'week',\n",
        "'few',\n",
        "'complain',\n",
        "'foods',\n",
        "'friend',\n",
        "'procedures',\n",
        "'extremely',\n",
        "'saturday',\n",
        "'right',\n",
        "'okay',\n",
        "'give',\n",
        "'gift',\n",
        "'checks',\n",
        "'supporting',\n",
        "'visited',\n",
        "'return',\n",
        "'coordination',\n",
        "'nothing',\n",
        "'head',\n",
        "'high',\n",
        "'busy',\n",
        "'please',\n",
        "'extra',\n",
        "'abdomen',\n",
        "'star',\n",
        "'information',\n",
        "'rating',\n",
        "'needs',\n",
        "'discount',\n",
        "'note',\n",
        "'feeling',\n",
        "'indeed'}\n",
        "\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words and co-occurrences with \"ultrasound\"\n",
        "word_counts = Counter()\n",
        "co_occurrences = defaultdict(int)\n",
        "ultrasound_reviews = []\n",
        "\n",
        "data['Reviews'].apply(lambda review: ultrasound_reviews.append(review) if 'screening' in review.lower() else None)\n",
        "\n",
        "for review in ultrasound_reviews:\n",
        "    words = preprocess(review)\n",
        "    unique_words = set(words)\n",
        "    if 'ultrasound' in unique_words:\n",
        "        for word in unique_words:\n",
        "            if word != 'screening':\n",
        "                co_occurrences[word] += 1\n",
        "\n",
        "# Normalize co-occurrence counts\n",
        "total_co_occurrences = sum(co_occurrences.values())\n",
        "normalized_co_occurrences = {word: count / total_co_occurrences for word, count in co_occurrences.items()}\n"
      ],
      "metadata": {
        "id": "3nDVOWrw589E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataFrame\n",
        "data_entries = []\n",
        "for word, score in normalized_co_occurrences.items():\n",
        "    if word in positive_words:\n",
        "        data_entries.append({'Category': 'Positive', 'Word': word, 'Relationship': score})\n",
        "    elif word in negative_words:\n",
        "        data_entries.append({'Category': 'Negative', 'Word': word, 'Relationship': score})\n",
        "    elif word in neutral_words:\n",
        "        data_entries.append({'Category': 'Neutral', 'Word': word, 'Relationship': score})\n",
        "\n",
        "# Create DataFrame\n",
        "sentiment_df = pd.DataFrame(data_entries)\n",
        "\n",
        "# Save to Excel\n",
        "sentiment_df.to_excel('screening_word_relationships.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "VwDvHF2G6R4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_excel('Google Health Screening.xlsx')  # Adjust the file path and sheet if necessary\n",
        "\n",
        "# Define word categories\n",
        "positive_words = {'good',\n",
        "'friendly',\n",
        "'helpful',\n",
        "'well',\n",
        "'fast',\n",
        "'great',\n",
        "'recommend',\n",
        "'efficient',\n",
        "'patient',\n",
        "'polite',\n",
        "'recommended',\n",
        "'professional',\n",
        "'thank',\n",
        "'excellent',\n",
        "'thanks',\n",
        "'smooth',\n",
        "'best',\n",
        "'comfortable',\n",
        "'pleasant',\n",
        "'satisfied',\n",
        "'happy',\n",
        "'clear',\n",
        "'impressed',\n",
        "'super',\n",
        "'better',\n",
        "'special',\n",
        "'affordable',\n",
        "'smoothly',\n",
        "'love',\n",
        "'clean',\n",
        "'comprehensive',\n",
        "'superb',\n",
        "'awesome',\n",
        "'systematic',\n",
        "'organised',\n",
        "'fantastic',\n",
        "'knowledgeable',\n",
        "'smile',\n",
        "'pretty',\n",
        "'appreciate',\n",
        "'wonderful',\n",
        "'positive',\n",
        "'organized',\n",
        "'approachable',\n",
        "'kudos',\n",
        "'efficiently',\n",
        "'responsive',\n",
        "'glad',\n",
        "'acceptable',\n",
        "'patience',\n",
        "'corporate',\n",
        "'amazing',\n",
        "'gentle'}\n",
        "negative_words = {'worst',\n",
        "'bad',\n",
        "'slow',\n",
        "'missed',\n",
        "'stress',\n",
        "'terrible',\n",
        "'delay',\n",
        "'horrible',\n",
        "'unpleasant',\n",
        "'worried'}\n",
        "neutral_words = {'screening',\n",
        "'health',\n",
        "'staff',\n",
        "'service',\n",
        "'hospital',\n",
        "'time',\n",
        "'experience',\n",
        "'waiting',\n",
        "'lunch',\n",
        "'provided',\n",
        "'first',\n",
        "'staffs',\n",
        "'process',\n",
        "'breakfast',\n",
        "'doctor',\n",
        "'nurses',\n",
        "'food',\n",
        "'report',\n",
        "'people',\n",
        "'wait',\n",
        "'free',\n",
        "'overall',\n",
        "'doctors',\n",
        "'customer',\n",
        "'package',\n",
        "'check',\n",
        "'services',\n",
        "'many',\n",
        "'would',\n",
        "'day',\n",
        "'patients',\n",
        "'ultrasound',\n",
        "'hours',\n",
        "'need',\n",
        "'today',\n",
        "'parking',\n",
        "'went',\n",
        "'long',\n",
        "'highly',\n",
        "'nurse',\n",
        "'registration',\n",
        "'make',\n",
        "'same',\n",
        "'medical',\n",
        "'still',\n",
        "'provide',\n",
        "'feel',\n",
        "'visit',\n",
        "'than',\n",
        "'dr',\n",
        "'during',\n",
        "'queue',\n",
        "'full',\n",
        "'number',\n",
        "'took',\n",
        "'cancer',\n",
        "'attentive',\n",
        "'name',\n",
        "'our',\n",
        "'nice',\n",
        "'team',\n",
        "'last',\n",
        "'quite',\n",
        "'take',\n",
        "'other',\n",
        "'care',\n",
        "'blood',\n",
        "'some',\n",
        "'definitely',\n",
        "'especially',\n",
        "'follow',\n",
        "'next',\n",
        "'got',\n",
        "'about',\n",
        "'waited',\n",
        "'angeline',\n",
        "'price',\n",
        "'screen',\n",
        "'annual',\n",
        "'now',\n",
        "'environment',\n",
        "'tests',\n",
        "'keep',\n",
        "'hour',\n",
        "'help',\n",
        "'sure',\n",
        "'consultation',\n",
        "'those',\n",
        "'department',\n",
        "'counter',\n",
        "'coming',\n",
        "'room',\n",
        "'ok',\n",
        "'flow',\n",
        "'early',\n",
        "'appointment',\n",
        "'kind',\n",
        "'year',\n",
        "'hope',\n",
        "'finished',\n",
        "'how',\n",
        "'ready',\n",
        "'avoid',\n",
        "'crowd',\n",
        "'such',\n",
        "'completed',\n",
        "'compared',\n",
        "'told',\n",
        "'turn',\n",
        "'result',\n",
        "'job',\n",
        "'review',\n",
        "'since',\n",
        "'start',\n",
        "'think',\n",
        "'treatment',\n",
        "'work',\n",
        "'serve',\n",
        "'less',\n",
        "'friends',\n",
        "'explanation',\n",
        "'results',\n",
        "'family',\n",
        "'promotion',\n",
        "'arrived',\n",
        "'screenings',\n",
        "'morning',\n",
        "'without',\n",
        "'system',\n",
        "'years',\n",
        "'find',\n",
        "'packages',\n",
        "'should',\n",
        "'floor',\n",
        "'received',\n",
        "'hospitality',\n",
        "'reports',\n",
        "'procedure',\n",
        "'helped',\n",
        "'chicken',\n",
        "'said',\n",
        "'later',\n",
        "'through',\n",
        "'explain',\n",
        "'explained',\n",
        "'warm',\n",
        "'checking',\n",
        "'healthy',\n",
        "'met',\n",
        "'handle',\n",
        "'thumbs',\n",
        "'meals',\n",
        "'plus',\n",
        "'must',\n",
        "'fasting',\n",
        "'simple',\n",
        "'appointments',\n",
        "'progress',\n",
        "'lady',\n",
        "'quick',\n",
        "'consultancy',\n",
        "'caring',\n",
        "'ensure',\n",
        "'offer',\n",
        "'assessment',\n",
        "'served',\n",
        "'reasonable',\n",
        "'available',\n",
        "'taken',\n",
        "'drinks',\n",
        "'tasty',\n",
        "'attending',\n",
        "'delicious',\n",
        "'guidance',\n",
        "'felt',\n",
        "'hospitals',\n",
        "'truly',\n",
        "'far',\n",
        "'meal',\n",
        "'doc',\n",
        "'reached',\n",
        "'treated',\n",
        "'complete',\n",
        "'opposite',\n",
        "'section',\n",
        "'packed',\n",
        "'easy',\n",
        "'examination',\n",
        "'made',\n",
        "'attended',\n",
        "'gave',\n",
        "'level',\n",
        "'stars',\n",
        "'home',\n",
        "'throughout',\n",
        "'however',\n",
        "'customers',\n",
        "'most',\n",
        "'god',\n",
        "'continue',\n",
        "'drs',\n",
        "'despite',\n",
        "'detailed',\n",
        "'tea',\n",
        "'entire',\n",
        "'way',\n",
        "'light',\n",
        "'space',\n",
        "'making',\n",
        "'improve',\n",
        "'body',\n",
        "'credit',\n",
        "'able',\n",
        "'sorry',\n",
        "'own',\n",
        "'longer',\n",
        "'collect',\n",
        "'mentioned',\n",
        "'answer',\n",
        "'officers',\n",
        "'thorough',\n",
        "'point',\n",
        "'info',\n",
        "'included',\n",
        "'attitude',\n",
        "'once',\n",
        "'complimentary',\n",
        "'hot',\n",
        "'reviews',\n",
        "'different',\n",
        "'covid',\n",
        "'sop',\n",
        "'finish',\n",
        "'management',\n",
        "'details',\n",
        "'phone',\n",
        "'hrs',\n",
        "'earlier',\n",
        "'payment',\n",
        "'private',\n",
        "'taking',\n",
        "'detail',\n",
        "'ecg',\n",
        "'scan',\n",
        "'want',\n",
        "'given',\n",
        "'difference',\n",
        "'heath',\n",
        "'over',\n",
        "'cheap',\n",
        "'weekday',\n",
        "'cost',\n",
        "'step',\n",
        "'assist',\n",
        "'eye',\n",
        "'wanted',\n",
        "'mom',\n",
        "'guide',\n",
        "'closely',\n",
        "'timer',\n",
        "'buffet',\n",
        "'personnel',\n",
        "'assisting',\n",
        "'quickly',\n",
        "'meet',\n",
        "'rest',\n",
        "'ensuring',\n",
        "'healthcare',\n",
        "'plenty',\n",
        "'yearly',\n",
        "'never',\n",
        "'whatsapp',\n",
        "'bone',\n",
        "'nathan',\n",
        "'vegetarian',\n",
        "'journey',\n",
        "'relatives',\n",
        "'month',\n",
        "'mandy',\n",
        "'courteous',\n",
        "'welcoming',\n",
        "'speed',\n",
        "'recently',\n",
        "'try',\n",
        "'providing',\n",
        "'large',\n",
        "'facilities',\n",
        "'pressure',\n",
        "'explaining',\n",
        "'eat',\n",
        "'trained',\n",
        "'money',\n",
        "'pasar',\n",
        "'chest',\n",
        "'takes',\n",
        "'normal',\n",
        "'slot',\n",
        "'walking',\n",
        "'similar',\n",
        "'absolutely',\n",
        "'ray',\n",
        "'email',\n",
        "'soon',\n",
        "'away',\n",
        "'urine',\n",
        "'file',\n",
        "'twice',\n",
        "'change',\n",
        "'loud',\n",
        "'leave',\n",
        "'inform',\n",
        "'xray',\n",
        "'week',\n",
        "'few',\n",
        "'complain',\n",
        "'foods',\n",
        "'friend',\n",
        "'procedures',\n",
        "'extremely',\n",
        "'saturday',\n",
        "'right',\n",
        "'okay',\n",
        "'give',\n",
        "'gift',\n",
        "'checks',\n",
        "'supporting',\n",
        "'visited',\n",
        "'return',\n",
        "'coordination',\n",
        "'nothing',\n",
        "'head',\n",
        "'high',\n",
        "'busy',\n",
        "'please',\n",
        "'extra',\n",
        "'abdomen',\n",
        "'star',\n",
        "'information',\n",
        "'rating',\n",
        "'needs',\n",
        "'discount',\n",
        "'note',\n",
        "'feeling',\n",
        "'indeed'}\n",
        "\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words and co-occurrences with \"ultrasound\"\n",
        "word_counts = Counter()\n",
        "co_occurrences = defaultdict(int)\n",
        "ultrasound_reviews = []\n",
        "\n",
        "data['Reviews'].apply(lambda review: ultrasound_reviews.append(review) if 'queue' in review.lower() else None)\n",
        "\n",
        "for review in ultrasound_reviews:\n",
        "    words = preprocess(review)\n",
        "    unique_words = set(words)\n",
        "    if 'ultrasound' in unique_words:\n",
        "        for word in unique_words:\n",
        "            if word != 'queue':\n",
        "                co_occurrences[word] += 1\n",
        "\n",
        "# Normalize co-occurrence counts\n",
        "total_co_occurrences = sum(co_occurrences.values())\n",
        "normalized_co_occurrences = {word: count / total_co_occurrences for word, count in co_occurrences.items()}\n"
      ],
      "metadata": {
        "id": "LHyvNqPl3gBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataFrame\n",
        "data_entries = []\n",
        "for word, score in normalized_co_occurrences.items():\n",
        "    if word in positive_words:\n",
        "        data_entries.append({'Category': 'Positive', 'Word': word, 'Relationship': score})\n",
        "    elif word in negative_words:\n",
        "        data_entries.append({'Category': 'Negative', 'Word': word, 'Relationship': score})\n",
        "    elif word in neutral_words:\n",
        "        data_entries.append({'Category': 'Neutral', 'Word': word, 'Relationship': score})\n",
        "\n",
        "# Create DataFrame\n",
        "sentiment_df = pd.DataFrame(data_entries)\n",
        "\n",
        "# Save to Excel\n",
        "sentiment_df.to_excel('queue_word_relationships.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "yr3ViDVi3y50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_excel('Google Health Screening.xlsx')  # Adjust the file path and sheet if necessary\n",
        "\n",
        "# Define word categories\n",
        "positive_words = {'good',\n",
        "'friendly',\n",
        "'helpful',\n",
        "'well',\n",
        "'fast',\n",
        "'great',\n",
        "'recommend',\n",
        "'efficient',\n",
        "'patient',\n",
        "'polite',\n",
        "'recommended',\n",
        "'professional',\n",
        "'thank',\n",
        "'excellent',\n",
        "'thanks',\n",
        "'smooth',\n",
        "'best',\n",
        "'comfortable',\n",
        "'pleasant',\n",
        "'satisfied',\n",
        "'happy',\n",
        "'clear',\n",
        "'impressed',\n",
        "'super',\n",
        "'better',\n",
        "'special',\n",
        "'affordable',\n",
        "'smoothly',\n",
        "'love',\n",
        "'clean',\n",
        "'comprehensive',\n",
        "'superb',\n",
        "'awesome',\n",
        "'systematic',\n",
        "'organised',\n",
        "'fantastic',\n",
        "'knowledgeable',\n",
        "'smile',\n",
        "'pretty',\n",
        "'appreciate',\n",
        "'wonderful',\n",
        "'positive',\n",
        "'organized',\n",
        "'approachable',\n",
        "'kudos',\n",
        "'efficiently',\n",
        "'responsive',\n",
        "'glad',\n",
        "'acceptable',\n",
        "'patience',\n",
        "'corporate',\n",
        "'amazing',\n",
        "'gentle'}\n",
        "negative_words = {'worst',\n",
        "'bad',\n",
        "'slow',\n",
        "'missed',\n",
        "'stress',\n",
        "'terrible',\n",
        "'delay',\n",
        "'horrible',\n",
        "'unpleasant',\n",
        "'worried'}\n",
        "neutral_words = {'screening',\n",
        "'health',\n",
        "'staff',\n",
        "'service',\n",
        "'hospital',\n",
        "'time',\n",
        "'experience',\n",
        "'waiting',\n",
        "'lunch',\n",
        "'provided',\n",
        "'first',\n",
        "'staffs',\n",
        "'process',\n",
        "'breakfast',\n",
        "'doctor',\n",
        "'nurses',\n",
        "'food',\n",
        "'report',\n",
        "'people',\n",
        "'wait',\n",
        "'free',\n",
        "'overall',\n",
        "'doctors',\n",
        "'customer',\n",
        "'package',\n",
        "'check',\n",
        "'services',\n",
        "'many',\n",
        "'would',\n",
        "'day',\n",
        "'patients',\n",
        "'ultrasound',\n",
        "'hours',\n",
        "'need',\n",
        "'today',\n",
        "'parking',\n",
        "'went',\n",
        "'long',\n",
        "'highly',\n",
        "'nurse',\n",
        "'registration',\n",
        "'make',\n",
        "'same',\n",
        "'medical',\n",
        "'still',\n",
        "'provide',\n",
        "'feel',\n",
        "'visit',\n",
        "'than',\n",
        "'dr',\n",
        "'during',\n",
        "'queue',\n",
        "'full',\n",
        "'number',\n",
        "'took',\n",
        "'cancer',\n",
        "'attentive',\n",
        "'name',\n",
        "'our',\n",
        "'nice',\n",
        "'team',\n",
        "'last',\n",
        "'quite',\n",
        "'take',\n",
        "'other',\n",
        "'care',\n",
        "'blood',\n",
        "'some',\n",
        "'definitely',\n",
        "'especially',\n",
        "'follow',\n",
        "'next',\n",
        "'got',\n",
        "'about',\n",
        "'waited',\n",
        "'angeline',\n",
        "'price',\n",
        "'screen',\n",
        "'annual',\n",
        "'now',\n",
        "'environment',\n",
        "'tests',\n",
        "'keep',\n",
        "'hour',\n",
        "'help',\n",
        "'sure',\n",
        "'consultation',\n",
        "'those',\n",
        "'department',\n",
        "'counter',\n",
        "'coming',\n",
        "'room',\n",
        "'ok',\n",
        "'flow',\n",
        "'early',\n",
        "'appointment',\n",
        "'kind',\n",
        "'year',\n",
        "'hope',\n",
        "'finished',\n",
        "'how',\n",
        "'ready',\n",
        "'avoid',\n",
        "'crowd',\n",
        "'such',\n",
        "'completed',\n",
        "'compared',\n",
        "'told',\n",
        "'turn',\n",
        "'result',\n",
        "'job',\n",
        "'review',\n",
        "'since',\n",
        "'start',\n",
        "'think',\n",
        "'treatment',\n",
        "'work',\n",
        "'serve',\n",
        "'less',\n",
        "'friends',\n",
        "'explanation',\n",
        "'results',\n",
        "'family',\n",
        "'promotion',\n",
        "'arrived',\n",
        "'screenings',\n",
        "'morning',\n",
        "'without',\n",
        "'system',\n",
        "'years',\n",
        "'find',\n",
        "'packages',\n",
        "'should',\n",
        "'floor',\n",
        "'received',\n",
        "'hospitality',\n",
        "'reports',\n",
        "'procedure',\n",
        "'helped',\n",
        "'chicken',\n",
        "'said',\n",
        "'later',\n",
        "'through',\n",
        "'explain',\n",
        "'explained',\n",
        "'warm',\n",
        "'checking',\n",
        "'healthy',\n",
        "'met',\n",
        "'handle',\n",
        "'thumbs',\n",
        "'meals',\n",
        "'plus',\n",
        "'must',\n",
        "'fasting',\n",
        "'simple',\n",
        "'appointments',\n",
        "'progress',\n",
        "'lady',\n",
        "'quick',\n",
        "'consultancy',\n",
        "'caring',\n",
        "'ensure',\n",
        "'offer',\n",
        "'assessment',\n",
        "'served',\n",
        "'reasonable',\n",
        "'available',\n",
        "'taken',\n",
        "'drinks',\n",
        "'tasty',\n",
        "'attending',\n",
        "'delicious',\n",
        "'guidance',\n",
        "'felt',\n",
        "'hospitals',\n",
        "'truly',\n",
        "'far',\n",
        "'meal',\n",
        "'doc',\n",
        "'reached',\n",
        "'treated',\n",
        "'complete',\n",
        "'opposite',\n",
        "'section',\n",
        "'packed',\n",
        "'easy',\n",
        "'examination',\n",
        "'made',\n",
        "'attended',\n",
        "'gave',\n",
        "'level',\n",
        "'stars',\n",
        "'home',\n",
        "'throughout',\n",
        "'however',\n",
        "'customers',\n",
        "'most',\n",
        "'god',\n",
        "'continue',\n",
        "'drs',\n",
        "'despite',\n",
        "'detailed',\n",
        "'tea',\n",
        "'entire',\n",
        "'way',\n",
        "'light',\n",
        "'space',\n",
        "'making',\n",
        "'improve',\n",
        "'body',\n",
        "'credit',\n",
        "'able',\n",
        "'sorry',\n",
        "'own',\n",
        "'longer',\n",
        "'collect',\n",
        "'mentioned',\n",
        "'answer',\n",
        "'officers',\n",
        "'thorough',\n",
        "'point',\n",
        "'info',\n",
        "'included',\n",
        "'attitude',\n",
        "'once',\n",
        "'complimentary',\n",
        "'hot',\n",
        "'reviews',\n",
        "'different',\n",
        "'covid',\n",
        "'sop',\n",
        "'finish',\n",
        "'management',\n",
        "'details',\n",
        "'phone',\n",
        "'hrs',\n",
        "'earlier',\n",
        "'payment',\n",
        "'private',\n",
        "'taking',\n",
        "'detail',\n",
        "'ecg',\n",
        "'scan',\n",
        "'want',\n",
        "'given',\n",
        "'difference',\n",
        "'heath',\n",
        "'over',\n",
        "'cheap',\n",
        "'weekday',\n",
        "'cost',\n",
        "'step',\n",
        "'assist',\n",
        "'eye',\n",
        "'wanted',\n",
        "'mom',\n",
        "'guide',\n",
        "'closely',\n",
        "'timer',\n",
        "'buffet',\n",
        "'personnel',\n",
        "'assisting',\n",
        "'quickly',\n",
        "'meet',\n",
        "'rest',\n",
        "'ensuring',\n",
        "'healthcare',\n",
        "'plenty',\n",
        "'yearly',\n",
        "'never',\n",
        "'whatsapp',\n",
        "'bone',\n",
        "'nathan',\n",
        "'vegetarian',\n",
        "'journey',\n",
        "'relatives',\n",
        "'month',\n",
        "'mandy',\n",
        "'courteous',\n",
        "'welcoming',\n",
        "'speed',\n",
        "'recently',\n",
        "'try',\n",
        "'providing',\n",
        "'large',\n",
        "'facilities',\n",
        "'pressure',\n",
        "'explaining',\n",
        "'eat',\n",
        "'trained',\n",
        "'money',\n",
        "'pasar',\n",
        "'chest',\n",
        "'takes',\n",
        "'normal',\n",
        "'slot',\n",
        "'walking',\n",
        "'similar',\n",
        "'absolutely',\n",
        "'ray',\n",
        "'email',\n",
        "'soon',\n",
        "'away',\n",
        "'urine',\n",
        "'file',\n",
        "'twice',\n",
        "'change',\n",
        "'loud',\n",
        "'leave',\n",
        "'inform',\n",
        "'xray',\n",
        "'week',\n",
        "'few',\n",
        "'complain',\n",
        "'foods',\n",
        "'friend',\n",
        "'procedures',\n",
        "'extremely',\n",
        "'saturday',\n",
        "'right',\n",
        "'okay',\n",
        "'give',\n",
        "'gift',\n",
        "'checks',\n",
        "'supporting',\n",
        "'visited',\n",
        "'return',\n",
        "'coordination',\n",
        "'nothing',\n",
        "'head',\n",
        "'high',\n",
        "'busy',\n",
        "'please',\n",
        "'extra',\n",
        "'abdomen',\n",
        "'star',\n",
        "'information',\n",
        "'rating',\n",
        "'needs',\n",
        "'discount',\n",
        "'note',\n",
        "'feeling',\n",
        "'indeed'}\n",
        "\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words and co-occurrences with \"ultrasound\"\n",
        "word_counts = Counter()\n",
        "co_occurrences = defaultdict(int)\n",
        "ultrasound_reviews = []\n",
        "\n",
        "data['Reviews'].apply(lambda review: ultrasound_reviews.append(review) if 'ecg' in review.lower() else None)\n",
        "\n",
        "for review in ultrasound_reviews:\n",
        "    words = preprocess(review)\n",
        "    unique_words = set(words)\n",
        "    if 'ultrasound' in unique_words:\n",
        "        for word in unique_words:\n",
        "            if word != 'ecg':\n",
        "                co_occurrences[word] += 1\n",
        "\n",
        "# Normalize co-occurrence counts\n",
        "total_co_occurrences = sum(co_occurrences.values())\n",
        "normalized_co_occurrences = {word: count / total_co_occurrences for word, count in co_occurrences.items()}\n"
      ],
      "metadata": {
        "id": "1OmluEZ-4Nuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataFrame\n",
        "data_entries = []\n",
        "for word, score in normalized_co_occurrences.items():\n",
        "    if word in positive_words:\n",
        "        data_entries.append({'Category': 'Positive', 'Word': word, 'Relationship': score})\n",
        "    elif word in negative_words:\n",
        "        data_entries.append({'Category': 'Negative', 'Word': word, 'Relationship': score})\n",
        "    elif word in neutral_words:\n",
        "        data_entries.append({'Category': 'Neutral', 'Word': word, 'Relationship': score})\n",
        "\n",
        "# Create DataFrame\n",
        "sentiment_df = pd.DataFrame(data_entries)\n",
        "\n",
        "# Save to Excel\n",
        "sentiment_df.to_excel('ecg_word_relationships.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "NTyW6JJ34TTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_excel('Google Health Screening.xlsx')  # Adjust the file path and sheet if necessary\n",
        "\n",
        "# Define word categories\n",
        "positive_words = {'good',\n",
        "'friendly',\n",
        "'helpful',\n",
        "'well',\n",
        "'fast',\n",
        "'great',\n",
        "'recommend',\n",
        "'efficient',\n",
        "'patient',\n",
        "'polite',\n",
        "'recommended',\n",
        "'professional',\n",
        "'thank',\n",
        "'excellent',\n",
        "'thanks',\n",
        "'smooth',\n",
        "'best',\n",
        "'comfortable',\n",
        "'pleasant',\n",
        "'satisfied',\n",
        "'happy',\n",
        "'clear',\n",
        "'impressed',\n",
        "'super',\n",
        "'better',\n",
        "'special',\n",
        "'affordable',\n",
        "'smoothly',\n",
        "'love',\n",
        "'clean',\n",
        "'comprehensive',\n",
        "'superb',\n",
        "'awesome',\n",
        "'systematic',\n",
        "'organised',\n",
        "'fantastic',\n",
        "'knowledgeable',\n",
        "'smile',\n",
        "'pretty',\n",
        "'appreciate',\n",
        "'wonderful',\n",
        "'positive',\n",
        "'organized',\n",
        "'approachable',\n",
        "'kudos',\n",
        "'efficiently',\n",
        "'responsive',\n",
        "'glad',\n",
        "'acceptable',\n",
        "'patience',\n",
        "'corporate',\n",
        "'amazing',\n",
        "'gentle'}\n",
        "negative_words = {'worst',\n",
        "'bad',\n",
        "'slow',\n",
        "'missed',\n",
        "'stress',\n",
        "'terrible',\n",
        "'delay',\n",
        "'horrible',\n",
        "'unpleasant',\n",
        "'worried'}\n",
        "neutral_words = {'screening',\n",
        "'health',\n",
        "'staff',\n",
        "'service',\n",
        "'hospital',\n",
        "'time',\n",
        "'experience',\n",
        "'waiting',\n",
        "'lunch',\n",
        "'provided',\n",
        "'first',\n",
        "'staffs',\n",
        "'process',\n",
        "'breakfast',\n",
        "'doctor',\n",
        "'nurses',\n",
        "'food',\n",
        "'report',\n",
        "'people',\n",
        "'wait',\n",
        "'free',\n",
        "'overall',\n",
        "'doctors',\n",
        "'customer',\n",
        "'package',\n",
        "'check',\n",
        "'services',\n",
        "'many',\n",
        "'would',\n",
        "'day',\n",
        "'patients',\n",
        "'ultrasound',\n",
        "'hours',\n",
        "'need',\n",
        "'today',\n",
        "'parking',\n",
        "'went',\n",
        "'long',\n",
        "'highly',\n",
        "'nurse',\n",
        "'registration',\n",
        "'make',\n",
        "'same',\n",
        "'medical',\n",
        "'still',\n",
        "'provide',\n",
        "'feel',\n",
        "'visit',\n",
        "'than',\n",
        "'dr',\n",
        "'during',\n",
        "'queue',\n",
        "'full',\n",
        "'number',\n",
        "'took',\n",
        "'cancer',\n",
        "'attentive',\n",
        "'name',\n",
        "'our',\n",
        "'nice',\n",
        "'team',\n",
        "'last',\n",
        "'quite',\n",
        "'take',\n",
        "'other',\n",
        "'care',\n",
        "'blood',\n",
        "'some',\n",
        "'definitely',\n",
        "'especially',\n",
        "'follow',\n",
        "'next',\n",
        "'got',\n",
        "'about',\n",
        "'waited',\n",
        "'angeline',\n",
        "'price',\n",
        "'screen',\n",
        "'annual',\n",
        "'now',\n",
        "'environment',\n",
        "'tests',\n",
        "'keep',\n",
        "'hour',\n",
        "'help',\n",
        "'sure',\n",
        "'consultation',\n",
        "'those',\n",
        "'department',\n",
        "'counter',\n",
        "'coming',\n",
        "'room',\n",
        "'ok',\n",
        "'flow',\n",
        "'early',\n",
        "'appointment',\n",
        "'kind',\n",
        "'year',\n",
        "'hope',\n",
        "'finished',\n",
        "'how',\n",
        "'ready',\n",
        "'avoid',\n",
        "'crowd',\n",
        "'such',\n",
        "'completed',\n",
        "'compared',\n",
        "'told',\n",
        "'turn',\n",
        "'result',\n",
        "'job',\n",
        "'review',\n",
        "'since',\n",
        "'start',\n",
        "'think',\n",
        "'treatment',\n",
        "'work',\n",
        "'serve',\n",
        "'less',\n",
        "'friends',\n",
        "'explanation',\n",
        "'results',\n",
        "'family',\n",
        "'promotion',\n",
        "'arrived',\n",
        "'screenings',\n",
        "'morning',\n",
        "'without',\n",
        "'system',\n",
        "'years',\n",
        "'find',\n",
        "'packages',\n",
        "'should',\n",
        "'floor',\n",
        "'received',\n",
        "'hospitality',\n",
        "'reports',\n",
        "'procedure',\n",
        "'helped',\n",
        "'chicken',\n",
        "'said',\n",
        "'later',\n",
        "'through',\n",
        "'explain',\n",
        "'explained',\n",
        "'warm',\n",
        "'checking',\n",
        "'healthy',\n",
        "'met',\n",
        "'handle',\n",
        "'thumbs',\n",
        "'meals',\n",
        "'plus',\n",
        "'must',\n",
        "'fasting',\n",
        "'simple',\n",
        "'appointments',\n",
        "'progress',\n",
        "'lady',\n",
        "'quick',\n",
        "'consultancy',\n",
        "'caring',\n",
        "'ensure',\n",
        "'offer',\n",
        "'assessment',\n",
        "'served',\n",
        "'reasonable',\n",
        "'available',\n",
        "'taken',\n",
        "'drinks',\n",
        "'tasty',\n",
        "'attending',\n",
        "'delicious',\n",
        "'guidance',\n",
        "'felt',\n",
        "'hospitals',\n",
        "'truly',\n",
        "'far',\n",
        "'meal',\n",
        "'doc',\n",
        "'reached',\n",
        "'treated',\n",
        "'complete',\n",
        "'opposite',\n",
        "'section',\n",
        "'packed',\n",
        "'easy',\n",
        "'examination',\n",
        "'made',\n",
        "'attended',\n",
        "'gave',\n",
        "'level',\n",
        "'stars',\n",
        "'home',\n",
        "'throughout',\n",
        "'however',\n",
        "'customers',\n",
        "'most',\n",
        "'god',\n",
        "'continue',\n",
        "'drs',\n",
        "'despite',\n",
        "'detailed',\n",
        "'tea',\n",
        "'entire',\n",
        "'way',\n",
        "'light',\n",
        "'space',\n",
        "'making',\n",
        "'improve',\n",
        "'body',\n",
        "'credit',\n",
        "'able',\n",
        "'sorry',\n",
        "'own',\n",
        "'longer',\n",
        "'collect',\n",
        "'mentioned',\n",
        "'answer',\n",
        "'officers',\n",
        "'thorough',\n",
        "'point',\n",
        "'info',\n",
        "'included',\n",
        "'attitude',\n",
        "'once',\n",
        "'complimentary',\n",
        "'hot',\n",
        "'reviews',\n",
        "'different',\n",
        "'covid',\n",
        "'sop',\n",
        "'finish',\n",
        "'management',\n",
        "'details',\n",
        "'phone',\n",
        "'hrs',\n",
        "'earlier',\n",
        "'payment',\n",
        "'private',\n",
        "'taking',\n",
        "'detail',\n",
        "'ecg',\n",
        "'scan',\n",
        "'want',\n",
        "'given',\n",
        "'difference',\n",
        "'heath',\n",
        "'over',\n",
        "'cheap',\n",
        "'weekday',\n",
        "'cost',\n",
        "'step',\n",
        "'assist',\n",
        "'eye',\n",
        "'wanted',\n",
        "'mom',\n",
        "'guide',\n",
        "'closely',\n",
        "'timer',\n",
        "'buffet',\n",
        "'personnel',\n",
        "'assisting',\n",
        "'quickly',\n",
        "'meet',\n",
        "'rest',\n",
        "'ensuring',\n",
        "'healthcare',\n",
        "'plenty',\n",
        "'yearly',\n",
        "'never',\n",
        "'whatsapp',\n",
        "'bone',\n",
        "'nathan',\n",
        "'vegetarian',\n",
        "'journey',\n",
        "'relatives',\n",
        "'month',\n",
        "'mandy',\n",
        "'courteous',\n",
        "'welcoming',\n",
        "'speed',\n",
        "'recently',\n",
        "'try',\n",
        "'providing',\n",
        "'large',\n",
        "'facilities',\n",
        "'pressure',\n",
        "'explaining',\n",
        "'eat',\n",
        "'trained',\n",
        "'money',\n",
        "'pasar',\n",
        "'chest',\n",
        "'takes',\n",
        "'normal',\n",
        "'slot',\n",
        "'walking',\n",
        "'similar',\n",
        "'absolutely',\n",
        "'ray',\n",
        "'email',\n",
        "'soon',\n",
        "'away',\n",
        "'urine',\n",
        "'file',\n",
        "'twice',\n",
        "'change',\n",
        "'loud',\n",
        "'leave',\n",
        "'inform',\n",
        "'xray',\n",
        "'week',\n",
        "'few',\n",
        "'complain',\n",
        "'foods',\n",
        "'friend',\n",
        "'procedures',\n",
        "'extremely',\n",
        "'saturday',\n",
        "'right',\n",
        "'okay',\n",
        "'give',\n",
        "'gift',\n",
        "'checks',\n",
        "'supporting',\n",
        "'visited',\n",
        "'return',\n",
        "'coordination',\n",
        "'nothing',\n",
        "'head',\n",
        "'high',\n",
        "'busy',\n",
        "'please',\n",
        "'extra',\n",
        "'abdomen',\n",
        "'star',\n",
        "'information',\n",
        "'rating',\n",
        "'needs',\n",
        "'discount',\n",
        "'note',\n",
        "'feeling',\n",
        "'indeed'}\n",
        "\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Count words and co-occurrences with \"ultrasound\"\n",
        "word_counts = Counter()\n",
        "co_occurrences = defaultdict(int)\n",
        "ultrasound_reviews = []\n",
        "\n",
        "data['Reviews'].apply(lambda review: ultrasound_reviews.append(review) if 'worst' in review.lower() else None)\n",
        "\n",
        "for review in ultrasound_reviews:\n",
        "    words = preprocess(review)\n",
        "    unique_words = set(words)\n",
        "    if 'ultrasound' in unique_words:\n",
        "        for word in unique_words:\n",
        "            if word != 'doctor':\n",
        "                co_occurrences[word] += 1\n",
        "\n",
        "# Normalize co-occurrence counts\n",
        "total_co_occurrences = sum(co_occurrences.values())\n",
        "normalized_co_occurrences = {word: count / total_co_occurrences for word, count in co_occurrences.items()}\n"
      ],
      "metadata": {
        "id": "1KYwxeIw4yTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataFrame\n",
        "data_entries = []\n",
        "for word, score in normalized_co_occurrences.items():\n",
        "    if word in positive_words:\n",
        "        data_entries.append({'Category': 'Positive', 'Word': word, 'Relationship': score})\n",
        "    elif word in negative_words:\n",
        "        data_entries.append({'Category': 'Negative', 'Word': word, 'Relationship': score})\n",
        "    elif word in neutral_words:\n",
        "        data_entries.append({'Category': 'Neutral', 'Word': word, 'Relationship': score})\n",
        "\n",
        "# Create DataFrame\n",
        "sentiment_df = pd.DataFrame(data_entries)\n",
        "\n",
        "# Save to Excel\n",
        "sentiment_df.to_excel('worst_word_relationships.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "PVQVV1-U491_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_words = {'good',\n",
        "'friendly',\n",
        "'helpful',\n",
        "'well',\n",
        "'fast',\n",
        "'great',\n",
        "'recommend',\n",
        "'efficient',\n",
        "'patient',\n",
        "'polite',\n",
        "'recommended',\n",
        "'professional',\n",
        "'thank',\n",
        "'excellent',\n",
        "'thanks',\n",
        "'smooth',\n",
        "'best',\n",
        "'comfortable',\n",
        "'pleasant',\n",
        "'satisfied',\n",
        "'happy',\n",
        "'clear',\n",
        "'impressed',\n",
        "'super',\n",
        "'better',\n",
        "'special',\n",
        "'affordable',\n",
        "'smoothly',\n",
        "'love',\n",
        "'clean',\n",
        "'comprehensive',\n",
        "'superb',\n",
        "'awesome',\n",
        "'systematic',\n",
        "'organised',\n",
        "'fantastic',\n",
        "'knowledgeable',\n",
        "'smile',\n",
        "'pretty',\n",
        "'appreciate',\n",
        "'wonderful',\n",
        "'positive',\n",
        "'organized',\n",
        "'approachable',\n",
        "'kudos',\n",
        "'efficiently',\n",
        "'responsive',\n",
        "'glad',\n",
        "'acceptable',\n",
        "'patience',\n",
        "'corporate',\n",
        "'amazing',\n",
        "'gentle'}\n",
        "negative_words = {'worst',\n",
        "'bad',\n",
        "'slow',\n",
        "'missed',\n",
        "'stress',\n",
        "'terrible',\n",
        "'delay',\n",
        "'horrible',\n",
        "'unpleasant',\n",
        "'worried'}"
      ],
      "metadata": {
        "id": "2FMuvfXO-3PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_excel('Google Health Screening.xlsx')  # Adjust the file path and sheet if necessary\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Analyze sentiment based on word counts\n",
        "def analyze_sentiment(review):\n",
        "    words = preprocess(review)\n",
        "    word_count = len(words)\n",
        "    positive_count = sum(1 for word in words if word in positive_words)\n",
        "    negative_count = sum(1 for word in words if word in negative_words)\n",
        "\n",
        "    if word_count == 0:\n",
        "        return (0, 0, 'Neutral')  # Handle edge case for empty reviews\n",
        "\n",
        "    percent_positive = positive_count / word_count\n",
        "    percent_negative = negative_count / word_count\n",
        "\n",
        "    # Define fuzzy sentiment based on the comparison of positive and negative proportions\n",
        "    if percent_positive > percent_negative:\n",
        "        fuzzy_sentiment = 'Positive'\n",
        "    elif percent_negative > percent_positive:\n",
        "        fuzzy_sentiment = 'Negative'\n",
        "    else:\n",
        "        fuzzy_sentiment = 'Neutral'\n",
        "\n",
        "    return (percent_positive, percent_negative, fuzzy_sentiment)\n",
        "\n",
        "# Apply sentiment analysis to each review\n",
        "data['% Positive Sentiment'], data['% Negative Sentiment'], data['Fuzzy Sentiment'] = zip(*data['Reviews'].map(analyze_sentiment))\n",
        "\n",
        "# Save the analyzed data to a new Excel file\n",
        "data.to_excel('reviewLine_sentiments.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "ckQ41UIz-_V8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}